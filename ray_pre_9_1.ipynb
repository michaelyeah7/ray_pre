{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d162e234",
   "metadata": {},
   "source": [
    "<img src=\"img/Ray.png\" width=\"800\">\n",
    "\n",
    "<br/><br/>\n",
    "<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88fca9d",
   "metadata": {},
   "source": [
    "## Bottleneck of Current ML \n",
    "### Goal: Distribute the job to as many as workers!\n",
    "<img src=\"img/workers.png\">\n",
    "\n",
    "\n",
    "\n",
    "<br/><br/>\n",
    "<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ca254d",
   "metadata": {},
   "source": [
    "## Competitors\n",
    "<img src=\"img/competitors.png\" width=\"800\">\n",
    "<br/><br/>\n",
    "<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af0f373",
   "metadata": {},
   "source": [
    "## The RISELab\n",
    "Previously UC berkeley AMPLab, develop and open-sourced Spark, Tachyon (now Alluxio), and Mesos.\n",
    "<img src=\"img/spark.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d9a4f9",
   "metadata": {},
   "source": [
    "# Ray Core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ce3359",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b086b7ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-01 16:06:02,411\tINFO services.py:1272 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "import time\n",
    "\n",
    "ray.init()\n",
    "\n",
    "@ray.remote\n",
    "def f(i):\n",
    "    time.sleep(1)\n",
    "    return i\n",
    "\n",
    "futures = [f.remote(i) for i in range(4)]\n",
    "print(ray.get(futures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99eb3965",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99113499",
   "metadata": {},
   "source": [
    "## Ray Init"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5cdfb3",
   "metadata": {},
   "source": [
    "<img src=\"img/architect.png\">\n",
    "\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48281ed1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-01 16:08:05,163\tINFO services.py:1272 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '192.168.100.204',\n",
       " 'raylet_ip_address': '192.168.100.204',\n",
       " 'redis_address': '192.168.100.204:6379',\n",
       " 'object_store_address': '/tmp/ray/session_2021-09-01_16-08-03_170786_2186/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2021-09-01_16-08-03_170786_2186/sockets/raylet',\n",
       " 'webui_url': '127.0.0.1:8265',\n",
       " 'session_dir': '/tmp/ray/session_2021-09-01_16-08-03_170786_2186',\n",
       " 'metrics_export_port': 63850,\n",
       " 'node_id': 'ce7db6210db290a98ab7f1e63adb52c103e230c24b53d40829bf8a94'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init(num_cpus=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675c6da3",
   "metadata": {},
   "source": [
    "## Ray Get/Put"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a0c4fd",
   "metadata": {},
   "source": [
    "### Expensive serialization and deserialization as well as data copying are a common performance bottleneck in distributed computing.\n",
    "<br></br>\n",
    "<img src=\"img/arrow.png\" width=\"500\">\n",
    "\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb448305",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClientObjectRef(50bc1e9bf6927fe48e7a10f3f79930f8b913e4f702a09fe301000000)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_id = ray.put(\"example\")\n",
    "x_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d62870c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'example'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.get(x_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e785ef8f",
   "metadata": {},
   "source": [
    "## Remote Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43c476ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def add2(a, b):\n",
    "    return a, [b,b]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c405d60c",
   "metadata": {},
   "source": [
    "### Invoke a task and Object Ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6e982e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectRef(480a853c2c4c6f27ffffffffffffffffffffffff0100000001000000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_id = add2.remote(1, 2)\n",
    "x_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc55c08b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, [2, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.get(x_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00b126cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@ray.remote(num_returns=3)\n",
    "def return_multiple():\n",
    "    return 1, 2, 3\n",
    "\n",
    "a_id, b_id, c_id = return_multiple.remote()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8559054e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectRef(623b26bdd75b28e9ffffffffffffffffffffffff0100000001000000)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c0cc96c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectRef(623b26bdd75b28e9ffffffffffffffffffffffff0100000002000000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0cf0493f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectRef(623b26bdd75b28e9ffffffffffffffffffffffff0100000003000000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdce07ba",
   "metadata": {},
   "source": [
    "## For loop to assign tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e26b4f",
   "metadata": {},
   "source": [
    "### futures = [f.remote(i) for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae569b97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-01 16:16:29,724\tINFO services.py:1272 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'object_refs' must either be an object ref or a list of object refs.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-34b73b9af037>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mfutures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/ray/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclient_mode_should_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ray/lib/python3.8/site-packages/ray/worker.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(object_refs, timeout)\u001b[0m\n\u001b[1;32m   1482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject_refs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m             raise ValueError(\"'object_refs' must either be an object ref \"\n\u001b[0m\u001b[1;32m   1485\u001b[0m                              \"or a list of object refs.\")\n\u001b[1;32m   1486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 'object_refs' must either be an object ref or a list of object refs."
     ]
    }
   ],
   "source": [
    "import ray\n",
    "import time\n",
    "\n",
    "ray.shutdown()\n",
    "ray.init()\n",
    "\n",
    "@ray.remote\n",
    "def f(i):\n",
    "    time.sleep(1)\n",
    "    return i\n",
    "\n",
    "futures = (f.remote(i) for i in range(4))\n",
    "print(ray.get(futures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe70d453",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37b1974",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "\n",
    "\n",
    "<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3147aad",
   "metadata": {},
   "source": [
    "# Ray Actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "67bc6cfe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-01 15:09:26,151\tINFO services.py:1272 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
      "2021-09-01 15:09:28,324\tINFO logservicer.py:102 -- New logs connection established. Total clients: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ClientActorHandle(5b4c2817f0d5e3a74ceae6ae01000000), ClientActorHandle(70f9d44f3938ba6143103d1001000000), ClientActorHandle(0adf7b103b53f8486aa5f13a01000000), ClientActorHandle(7ab7b024c3b4ffb7ab785d8901000000)]\n",
      "[1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "\n",
    "ray.shutdown()\n",
    "ray.init()\n",
    "\n",
    "@ray.remote\n",
    "class Counter(object):\n",
    "    def __init__(self):\n",
    "        self.n = 0\n",
    "    def increment(self):\n",
    "        self.n += 1\n",
    "    def read(self):\n",
    "        return self.n\n",
    "    \n",
    "counters = [Counter.remote() for i in range(4)]\n",
    "print(counters)\n",
    "[c.increment.remote() for c in counters]\n",
    "futures = [c.read.remote() for c in counters]\n",
    "print(ray.get(futures))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c778b7e",
   "metadata": {},
   "source": [
    "## Parameter Server\n",
    "\n",
    "<br></br>\n",
    "\n",
    "<img src=\"img/parameter_server.png\" width=\"700\">\n",
    "\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8396dbc4",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09475de1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from filelock import FileLock\n",
    "import numpy as np\n",
    "\n",
    "import ray\n",
    "\n",
    "\n",
    "def get_data_loader():\n",
    "    \"\"\"Safely downloads data. Returns training/validation set dataloader.\"\"\"\n",
    "    mnist_transforms = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Normalize((0.1307, ), (0.3081, ))])\n",
    "\n",
    "    # We add FileLock here because multiple workers will want to\n",
    "    # download data, and this may cause overwrites since\n",
    "    # DataLoader is not threadsafe.\n",
    "    with FileLock(os.path.expanduser(\"~/data.lock\")):\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            datasets.MNIST(\n",
    "                \"~/data\",\n",
    "                train=True,\n",
    "                download=True,\n",
    "                transform=mnist_transforms),\n",
    "            batch_size=128,\n",
    "            shuffle=True)\n",
    "        test_loader = torch.utils.data.DataLoader(\n",
    "            datasets.MNIST(\"~/data\", train=False, transform=mnist_transforms),\n",
    "            batch_size=128,\n",
    "            shuffle=True)\n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "def evaluate(model, test_loader):\n",
    "    \"\"\"Evaluates the accuracy of the model on a validation dataset.\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(test_loader):\n",
    "            # This is only set to finish evaluation faster.\n",
    "            if batch_idx * len(data) > 1024:\n",
    "                break\n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "    return 100. * correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb305f3d",
   "metadata": {},
   "source": [
    "### Define Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf0b587f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    \"\"\"Small ConvNet for MNIST.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 3, kernel_size=3)\n",
    "        self.fc = nn.Linear(192, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 3))\n",
    "        x = x.view(-1, 192)\n",
    "        x = self.fc(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "    def get_weights(self):\n",
    "        return {k: v.cpu() for k, v in self.state_dict().items()}\n",
    "\n",
    "    def set_weights(self, weights):\n",
    "        self.load_state_dict(weights)\n",
    "\n",
    "    def get_gradients(self):\n",
    "        grads = []\n",
    "        for p in self.parameters():\n",
    "            grad = None if p.grad is None else p.grad.data.cpu().numpy()\n",
    "            grads.append(grad)\n",
    "        return grads\n",
    "\n",
    "    def set_gradients(self, gradients):\n",
    "        for g, p in zip(gradients, self.parameters()):\n",
    "            if g is not None:\n",
    "                p.grad = torch.from_numpy(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08f9aa6",
   "metadata": {},
   "source": [
    "## Define Sever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e8ba4070",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# @ray.remote\n",
    "class ParameterServer(object):\n",
    "    def __init__(self, lr):\n",
    "        self.model = ConvNet()\n",
    "        self.optimizer = torch.optim.SGD(self.model.parameters(), lr=lr)\n",
    "\n",
    "    def apply_gradients(self, gradients):\n",
    "#         gradients = ray.get(*gradients)\n",
    "        print(\"gradeints in ps\",gradients)\n",
    "        summed_gradients = [\n",
    "            np.stack(gradient_zip).sum(axis=0)\n",
    "            for gradient_zip in zip(gradients)\n",
    "        ]\n",
    "        self.optimizer.zero_grad()\n",
    "        self.model.set_gradients(summed_gradients) # gradient = summend_gradient\n",
    "        self.optimizer.step() # w -= lr * (gradient + optimizer_gradient)\n",
    "        return self.model.get_weights()\n",
    "\n",
    "    def get_weights(self):\n",
    "        return self.model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "27a09491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp [3 3 3]\n",
      "temp [7 7 7]\n"
     ]
    }
   ],
   "source": [
    "gradeint_1 = np.array([[1,1,1],[3,3,3]])\n",
    "gradeint_2 = np.array([[2,2,2],[4,4,4]])\n",
    "\n",
    "gradients = [gradeint_1, gradeint_2]\n",
    "\n",
    "for gradient_zip in zip(*gradients):\n",
    "    temp = np.array(gradient_zip).sum(axis=0)\n",
    "    print(\"temp\",temp)\n",
    "#     stack = np.stack(gradient_zip).sum(axis=0)\n",
    "#     print(\"stack\",stack) \n",
    "#     print(\"gradient_zip\",gradient_zip) \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d12583",
   "metadata": {},
   "source": [
    "## Define Worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "105df8ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "class DataWorker(object):\n",
    "    def __init__(self):\n",
    "        self.model = ConvNet()\n",
    "        self.data_iterator = iter(get_data_loader()[0])\n",
    "\n",
    "    def compute_gradients(self, weights):\n",
    "        self.model.set_weights(weights)\n",
    "        try:\n",
    "            data, target = next(self.data_iterator)\n",
    "        except StopIteration:  # When the epoch ends, start a new epoch.\n",
    "            self.data_iterator = iter(get_data_loader()[0])\n",
    "            data, target = next(self.data_iterator)\n",
    "        self.model.zero_grad()\n",
    "        output = self.model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        return self.model.get_gradients()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "de432917",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=587)\u001b[0m /Users/xieguo/miniconda3/envs/ray/lib/python3.8/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "\u001b[2m\u001b[36m(pid=587)\u001b[0m   return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n",
      "\u001b[2m\u001b[36m(pid=587)\u001b[0m /Users/xieguo/miniconda3/envs/ray/lib/python3.8/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "\u001b[2m\u001b[36m(pid=587)\u001b[0m   return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n",
      "\u001b[2m\u001b[36m(pid=582)\u001b[0m /Users/xieguo/miniconda3/envs/ray/lib/python3.8/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "\u001b[2m\u001b[36m(pid=582)\u001b[0m   return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n",
      "\u001b[2m\u001b[36m(pid=582)\u001b[0m /Users/xieguo/miniconda3/envs/ray/lib/python3.8/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "\u001b[2m\u001b[36m(pid=582)\u001b[0m   return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "workers = [DataWorker.remote() for i in range(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b8d647b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ClientActorHandle(a7a9ef38db64f85aa11dffee01000000),\n",
       " ClientActorHandle(44c79a7b4144f6c4919722dc01000000)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9694c25c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-01 17:28:45,290\tINFO services.py:1272 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running synchronous parameter server training.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2876)\u001b[0m /Users/xieguo/miniconda3/envs/ray/lib/python3.8/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "\u001b[2m\u001b[36m(pid=2876)\u001b[0m   return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n",
      "\u001b[2m\u001b[36m(pid=2872)\u001b[0m /Users/xieguo/miniconda3/envs/ray/lib/python3.8/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "\u001b[2m\u001b[36m(pid=2872)\u001b[0m   return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradeints in ps [[array([[[[ 0.35065064,  0.3205852 ,  0.2195741 ],\n",
      "         [ 0.26225773,  0.20988001,  0.08071565],\n",
      "         [ 0.1556414 ,  0.06346474,  0.02011846]]],\n",
      "\n",
      "\n",
      "       [[[ 0.04883697,  0.03587123,  0.06884987],\n",
      "         [ 0.13784017,  0.10605384,  0.06080383],\n",
      "         [ 0.137815  ,  0.11534718,  0.05148438]]],\n",
      "\n",
      "\n",
      "       [[[-0.04346804, -0.02496378, -0.01449243],\n",
      "         [-0.02751596, -0.02145926,  0.00279573],\n",
      "         [-0.02471375, -0.01859206,  0.00035154]]]], dtype=float32), array([0.03885732, 0.09216283, 0.06102588], dtype=float32), array([[ 0.00110306,  0.00133766,  0.00110306, ...,  0.03064501,\n",
      "         0.02688601,  0.02755568],\n",
      "       [ 0.00423381,  0.00460703,  0.00423381, ...,  0.0808224 ,\n",
      "         0.10532589,  0.10709234],\n",
      "       [-0.00047816, -0.00033962, -0.00047816, ..., -0.0156629 ,\n",
      "        -0.01017844, -0.00732313],\n",
      "       ...,\n",
      "       [-0.00283323, -0.00272066, -0.00283323, ..., -0.08077073,\n",
      "        -0.07326441, -0.07270986],\n",
      "       [-0.00137135, -0.00127145, -0.00137135, ..., -0.01776314,\n",
      "        -0.0324154 , -0.03533481],\n",
      "       [ 0.00177995,  0.00205252,  0.00177995, ...,  0.04083113,\n",
      "         0.04283772,  0.04440925]], dtype=float32), array([ 0.03714748,  0.1425812 , -0.01610271, -0.01156189, -0.03822267,\n",
      "       -0.00019192, -0.03199578, -0.09541413, -0.04618257,  0.05994301],\n",
      "      dtype=float32)], [array([[[[ 0.25755224,  0.2403244 ,  0.18792512],\n",
      "         [ 0.15268323,  0.15556152,  0.11170372],\n",
      "         [ 0.06522439,  0.02105051,  0.03629712]]],\n",
      "\n",
      "\n",
      "       [[[ 0.03536456,  0.0568661 ,  0.07111618],\n",
      "         [ 0.11707995,  0.10761566,  0.0739435 ],\n",
      "         [ 0.09777232,  0.07900459,  0.0355344 ]]],\n",
      "\n",
      "\n",
      "       [[[-0.02654002, -0.03355483, -0.01420432],\n",
      "         [-0.02393058, -0.02802381,  0.00879278],\n",
      "         [-0.02273038, -0.0223288 , -0.00859028]]]], dtype=float32), array([0.04500445, 0.03406609, 0.07720958], dtype=float32), array([[-6.6383526e-04, -6.6383526e-04, -5.2225334e-04, ...,\n",
      "        -1.2042165e-02, -1.6333856e-02, -1.6962752e-02],\n",
      "       [ 3.8995284e-03,  3.8995284e-03,  4.3165321e-03, ...,\n",
      "         6.4323708e-02,  9.4698176e-02,  9.9306539e-02],\n",
      "       [-1.3450782e-03, -1.3450782e-03, -3.0054795e-03, ...,\n",
      "        -3.0940359e-02, -3.2618616e-02, -3.4300640e-02],\n",
      "       ...,\n",
      "       [-1.8000556e-03, -1.8000556e-03, -1.6634070e-03, ...,\n",
      "        -3.9676383e-02, -4.7295868e-02, -4.5891501e-02],\n",
      "       [ 8.0465572e-05,  8.0465572e-05,  1.8705739e-04, ...,\n",
      "         3.9568879e-03,  6.9119041e-03,  2.0355443e-03],\n",
      "       [ 8.2945288e-04,  8.2945288e-04,  1.0795741e-03, ...,\n",
      "         3.0893246e-02,  2.3957003e-02,  2.1108953e-02]], dtype=float32), array([-0.02235583,  0.13132353, -0.04529789, -0.00448358,  0.00518915,\n",
      "        0.01271794, -0.04711639, -0.06062005,  0.00270982,  0.02793329],\n",
      "      dtype=float32)]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2876)\u001b[0m /Users/xieguo/miniconda3/envs/ray/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ../c10/core/TensorImpl.h:1156.)\n",
      "\u001b[2m\u001b[36m(pid=2876)\u001b[0m   return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "/Users/xieguo/miniconda3/envs/ray/lib/python3.8/site-packages/numpy/core/shape_base.py:420: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arrays = [asanyarray(arr) for arr in arrays]\n",
      "\u001b[2m\u001b[36m(pid=2872)\u001b[0m /Users/xieguo/miniconda3/envs/ray/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ../c10/core/TensorImpl.h:1156.)\n",
      "\u001b[2m\u001b[36m(pid=2872)\u001b[0m   return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-30a11368fd7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m#     print(\"gradients\",gradients)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m#     current_weights = ps.apply_gradients(*gradients)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mcurrent_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-52-cc2d342729cb>\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, gradients)\u001b[0m\n\u001b[1;32m     13\u001b[0m         ]\n\u001b[1;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummed_gradients\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# gradient = summend_gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# w -= lr * (gradient + optimizer_gradient)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-b62a31994f0b>\u001b[0m in \u001b[0;36mset_gradients\u001b[0;34m(self, gradients)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."
     ]
    }
   ],
   "source": [
    "iterations = 200\n",
    "num_workers = 2\n",
    "\n",
    "ray.shutdown()\n",
    "ray.init(ignore_reinit_error=True)\n",
    "# ps = ParameterServer.remote(1e-2)\n",
    "ps = ParameterServer(1e-2)\n",
    "workers = [DataWorker.remote() for i in range(num_workers)]\n",
    "\n",
    "model = ConvNet()\n",
    "test_loader = get_data_loader()[1]\n",
    "\n",
    "print(\"Running synchronous parameter server training.\")\n",
    "# current_weights = ps.get_weights.remote()\n",
    "current_weights = ps.get_weights()\n",
    "# current_weights = ray.get()\n",
    "for i in range(iterations):\n",
    "    gradients = [\n",
    "        worker.compute_gradients.remote(current_weights) for worker in workers\n",
    "    ]\n",
    "    print()\n",
    "    # Calculate update after all gradients are available.\n",
    "#     current_weights = ps.apply_gradients.remote(*gradients)\n",
    "    gradients = ray.get(gradients)\n",
    "#     print(\"gradients\",gradients)\n",
    "#     current_weights = ps.apply_gradients(*gradients)\n",
    "    current_weights = ps.apply_gradients(gradients)\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        # Evaluate the current model.\n",
    "        model.set_weights(ray.get(current_weights))\n",
    "        accuracy = evaluate(model, test_loader)\n",
    "        print(\"Iter {}: \\taccuracy is {:.1f}\".format(i, accuracy))\n",
    "\n",
    "print(\"Final accuracy is {:.1f}.\".format(accuracy))\n",
    "# Clean up Ray resources and processes before the next example.\n",
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577c04dd",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ray",
   "language": "python",
   "name": "ray"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
